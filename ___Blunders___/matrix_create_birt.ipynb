{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "import face_recognition\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import urllib.request\n",
    "from pytube import YouTube\n",
    "import os\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate speaker position relative to the center\n",
    "def calculate_speaker_position(frame, shoulder_midpoint_x):\n",
    "    frame_width = frame.shape[1]\n",
    "    speaker_position = shoulder_midpoint_x - frame_width / 2\n",
    "    return speaker_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_transcript_with_timestamps(video_id):\n",
    "    try:\n",
    "        # video_id = video_url.split(\"v=\")[1]\n",
    "        transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "        transcript_text = \"\"\n",
    "\n",
    "        for entry in transcript:\n",
    "            start = entry[\"start\"]\n",
    "            text = entry[\"text\"]\n",
    "            transcript_text += f\"[{start:.2f}] {text}\\n\"\n",
    "\n",
    "        return transcript_text\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "    \n",
    "# Load pre-trained BERT model and tokenizer\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "def get_text_embedding(sentence):\n",
    "    # Tokenize the sentence and generate embeddings\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    outputs = model(**inputs)\n",
    "    embeddings = outputs.pooler_output\n",
    "    # embeddings will contain the contextual embeddings for each token in the sentence\n",
    "    one_dimensional_array = torch.cat([t for t in embeddings], dim=0)\n",
    "    # Convert the 1D tensor to a Python list\n",
    "    flattened_list = one_dimensional_array.view(-1).detach().tolist()\n",
    "    return flattened_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def convert_to_float(s):\n",
    "    if isinstance(s, (int, float)):\n",
    "        return s\n",
    "    s = s.strip().lower()\n",
    "    multiplier = 1.0\n",
    "\n",
    "    if s.endswith('k'):\n",
    "        multiplier = 1e3\n",
    "        s = s[:-1]\n",
    "    elif s.endswith('m'):\n",
    "        multiplier = 1e6\n",
    "        s = s[:-1]\n",
    "\n",
    "    # Handle 'K', 'M', 'B', 'T', etc.\n",
    "    if s.endswith('k'):\n",
    "        multiplier *= 1e3\n",
    "        s = s[:-1]\n",
    "    elif s.endswith('m'):\n",
    "        multiplier *= 1e6\n",
    "        s = s[:-1]\n",
    "    elif s.endswith('b'):\n",
    "        multiplier *= 1e9\n",
    "        s = s[:-1]\n",
    "    elif s.endswith('t'):\n",
    "        multiplier *= 1e12\n",
    "        s = s[:-1]\n",
    "\n",
    "    # Convert to float or log scale float\n",
    "    try:\n",
    "        result = float(s) * multiplier\n",
    "    except ValueError:\n",
    "        # Handle the case where the input is not a valid number\n",
    "        result = None\n",
    "\n",
    "    return result\n",
    "\n",
    "# # Examples\n",
    "# numbers = ['13M', '7.7K', '3.14k','900m','09.0']\n",
    "\n",
    "# for num_str in numbers:\n",
    "#     converted_num = convert_to_float(num_str)\n",
    "#     print(f\"{num_str}: {converted_num}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "maxLengthOfEmbedding = 768\n",
    "\n",
    "def calculate_avg_words_between_timestamps(file_path, video_length_seconds):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    timestamps = []\n",
    "    texts = []\n",
    "\n",
    "    timestamp_pattern = re.compile(r'\\[(\\d+\\.\\d+)\\]\\s(.+)')\n",
    "\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        line = lines[i]\n",
    "        match = re.match(timestamp_pattern, line)\n",
    "        if match:\n",
    "            timestamp = float(match.group(1))\n",
    "            text = match.group(2)\n",
    "            \n",
    "            # Check if the text continues on the next line\n",
    "            while i + 1 < len(lines) and not re.match(timestamp_pattern, lines[i + 1]):\n",
    "                i += 1\n",
    "                text += \" \" + lines[i].strip()\n",
    "\n",
    "            timestamps.append(round(timestamp))\n",
    "            texts.append(text)\n",
    "        i += 1\n",
    "\n",
    "    # Calculate average number of words between each timestamp\n",
    "    # avg_words_list = []\n",
    "    words_in_each_second = [0] * math.floor(video_length_seconds)\n",
    "    words_embedding = [np.zeros(maxLengthOfEmbedding)] * math.floor(video_length_seconds)\n",
    "    for i in range(len(timestamps) - 1):\n",
    "        start_time = timestamps[i]\n",
    "        # if i == len(timestamps) - 1:\n",
    "        #     end_time = video_length_seconds\n",
    "        # else\n",
    "        end_time = timestamps[i + 1]\n",
    "        # words_between = 0\n",
    "        count = end_time-start_time\n",
    "        words_between = len(texts[i].split())\n",
    "\n",
    "        # for j in range(len(texts)):\n",
    "        #     if start_time <= float(timestamps[j]) < end_time:\n",
    "        #         words_between += len(texts[j].split())\n",
    "        #         count += 1\n",
    "\n",
    "        avg_words = math.ceil(words_between / count) if count > 0 else 0\n",
    "        words_taken = 0\n",
    "        for k in range(count):\n",
    "            # words_embedding_each_second =  [0] * (maxLengthOfEmbedding)\n",
    "            if(words_taken >= words_between):\n",
    "                # padded_embedding =  [0] * (maxLengthOfEmbedding)\n",
    "                # for l in range(count-k):\n",
    "                #     words_embedding.append(padded_embedding)\n",
    "                    # words_in_each_second[timestamps[i]+k] = avg_words\n",
    "                break\n",
    "            if(words_taken + avg_words > words_between):\n",
    "                avg_words = words_between - words_taken\n",
    "            \n",
    "            words_in_each_second[timestamps[i]+k] = avg_words\n",
    "            sentence = texts[i][words_taken:words_taken + avg_words]\n",
    "            embedding = get_text_embedding(sentence)\n",
    "            if len(embedding) >= (maxLengthOfEmbedding):\n",
    "                padded_embedding = embedding[:maxLengthOfEmbedding]\n",
    "            else:\n",
    "                padded_embedding = np.pad(embedding, (0, maxLengthOfEmbedding - len(embedding)), mode='constant')\n",
    "\n",
    "            words_taken += avg_words\n",
    "            # print(padded_embedding)\n",
    "            # print(\"padded embedding\")\n",
    "            # print(len(padded_embedding))\n",
    "            words_embedding[timestamps[i]+k] = padded_embedding\n",
    "\n",
    "        # avg_words_list.append(avg_words)\n",
    "    print(\"Words in each second\")\n",
    "    print(len(words_in_each_second))\n",
    "    print(\"Words embedding\")\n",
    "    print(len(words_embedding))\n",
    "    return words_in_each_second, words_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = []\n",
    "emotion_labels = ['Anger', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprised', 'Neutral']\n",
    "emotion_model = load_model('emotion_model.h5')\n",
    "face_haar_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "def one_hot_encode(number, num_classes=7):\n",
    "    \"\"\"\n",
    "    One-hot encodes a number from 1 to num_classes.\n",
    "    \"\"\"\n",
    "    encoding = [0] * num_classes\n",
    "    encoding[number - 1] = 1\n",
    "    return encoding\n",
    "\n",
    "def get_emotion(frame):\n",
    "    frame_grey = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_haar_cascade.detectMultiScale(frame_grey)\n",
    "    if len(faces) > 0:\n",
    "        (x, y, w, h) = faces[0]\n",
    "        cv2.rectangle(frame, pt1=(x, y), pt2=(x + w, y + h), color=(0, 0, 255), thickness=2)\n",
    "        roi_gray = frame_grey[y - 5:y + h + 5, x - 5:x + w + 5]\n",
    "        if not roi_gray.size == 0:\n",
    "            roi_gray = cv2.resize(roi_gray, (48, 48))\n",
    "            image_pixels = img_to_array(roi_gray)\n",
    "            image_pixels = np.expand_dims(image_pixels, axis=0)\n",
    "        else:\n",
    "            image_pixels = None\n",
    "            # matrxOfCurrentSecond.append(0)\n",
    "            return [0,0,0,0,0,0,0]\n",
    "        image_pixels /= 255\n",
    "        predictions = emotion_model.predict(image_pixels)\n",
    "        max_index = np.argmax(predictions[0])\n",
    "        detected_emotion = emotion_labels[max_index]\n",
    "        emotions.append(detected_emotion)\n",
    "        # matrxOfCurrentSecond.append(max_index + 1)\n",
    "        return one_hot_encode(max_index + 1)\n",
    "    else:\n",
    "        emotions.append(None)\n",
    "        # matrxOfCurrentSecond.append(0)\n",
    "        return [0,0,0,0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "mp_holistic = mp.solutions.holistic\n",
    "holistic_model = mp_holistic.Holistic(\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "def get_head_turn_angle(results):\n",
    "    list_of_head_turn_angles = []\n",
    "    left_eye = results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_EYE_INNER]\n",
    "    right_eye = results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_EYE_INNER]\n",
    "    nose = results.pose_landmarks.landmark[mp_pose.PoseLandmark.NOSE]\n",
    "    if left_eye and right_eye and nose:\n",
    "        eye_line_vector = np.array([right_eye.x - left_eye.x, right_eye.y - left_eye.y])\n",
    "        eye_left_nose_vector = np.array([nose.x - left_eye.x, nose.y - left_eye.y])\n",
    "        eye_right_nose_vector = np.array([right_eye.x - nose.x, right_eye.y - nose.y])\n",
    "\n",
    "        dot_product_left = np.dot(eye_line_vector, eye_left_nose_vector)\n",
    "        eye_line_magnitude = np.linalg.norm(eye_line_vector)\n",
    "        eye_left_nose_magnitude = np.linalg.norm(eye_left_nose_vector)\n",
    "\n",
    "        dot_product_right = np.dot(eye_line_vector, eye_right_nose_vector)\n",
    "        eye_right_nose_magnitude = np.linalg.norm(eye_right_nose_vector)\n",
    "\n",
    "        cosine_angle_left = dot_product_left / (eye_line_magnitude * eye_left_nose_magnitude)\n",
    "        cosine_angle_right = dot_product_right / (eye_line_magnitude * eye_right_nose_magnitude)\n",
    "\n",
    "        head_turn_angle_left = np.arccos(cosine_angle_left) * (180 / np.pi)\n",
    "        head_turn_angle_right = np.arccos(cosine_angle_right) * (180 / np.pi)\n",
    "\n",
    "        list_of_head_turn_angles.append(head_turn_angle_left)\n",
    "        list_of_head_turn_angles.append(head_turn_angle_right)\n",
    "    else:\n",
    "        list_of_head_turn_angles.append(0)\n",
    "        list_of_head_turn_angles.append(0)\n",
    "    return list_of_head_turn_angles\n",
    "\n",
    "def get_shoulder_midpoint(results):\n",
    "    shoulder_midpoints = []\n",
    "    left_shoulder = results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER]\n",
    "    right_shoulder = results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER]\n",
    "\n",
    "    if left_shoulder and right_shoulder:\n",
    "        shoulder_midpoint_x = (left_shoulder.x + right_shoulder.x) / 2\n",
    "        shoulder_midpoints.append(shoulder_midpoint_x)\n",
    "    else:\n",
    "        shoulder_midpoints.append(0)\n",
    "    return shoulder_midpoints\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, activation='relu', input_shape=(None, 1376)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Define your model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu'),  # Remove input_shape\n",
    "    Dense(1)  # Modify output layer as needed\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mse')  # Modify loss function and optimizer as needed\n",
    "\n",
    "# Load data from files in DataSetFeatures and Rating directories\n",
    "data_dir = 'DataSetFeatures'\n",
    "label_dir = 'Rating'\n",
    "\n",
    "data_files = os.listdir(data_dir)\n",
    "label_files = os.listdir(label_dir)\n",
    "\n",
    "# Ensure that the files are sorted in the same order\n",
    "data_files.sort()\n",
    "label_files.sort()\n",
    "\n",
    "# Initialize lists to store features and labels\n",
    "matrixOfVideos = []\n",
    "popularity_labels = []\n",
    "\n",
    "for data_file, label_file in zip(data_files, label_files):\n",
    "    # Load features from data file\n",
    "    features = np.load(os.path.join(data_dir, data_file))\n",
    "\n",
    "    # Load label from label file\n",
    "    label = np.load(os.path.join(label_dir, label_file))\n",
    "\n",
    "    matrixOfVideos.append(features)\n",
    "    popularity_labels.append(label)\n",
    "\n",
    "# Pad sequences to ensure they have the same length\n",
    "matrixOfVideos_padded = pad_sequences(matrixOfVideos, dtype='float32', padding='post', truncating='post')\n",
    "\n",
    "popularity_labels = np.array(popularity_labels)\n",
    "\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model.fit(matrixOfVideos_padded, popularity_labels, epochs=1000, batch_size=30, validation_split=0.0, callbacks=[TensorBoard()])\n",
    "\n",
    "# Save the model\n",
    "model.save('model.h5')\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(matrixOfVideos_padded)\n",
    "# len(matrixOfVideos)\n",
    "len(popularity_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow.keras.backend as K\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import re\n",
    "\n",
    "# Define custom metric if needed\n",
    "def mse(y_true, y_pred):\n",
    "    return K.mean(K.square(y_pred - y_true), axis=-1)\n",
    "\n",
    "# Path to your model\n",
    "model_path = 'model.h5'\n",
    "\n",
    "# Load the model with custom objects\n",
    "model = load_model(model_path, custom_objects={'mse': mse})\n",
    "\n",
    "# Test data directories\n",
    "test_data_dir = 'DataSetFeatures'\n",
    "test_label_dir = 'Rating'\n",
    "\n",
    "test_data_files = os.listdir(test_data_dir)\n",
    "test_label_files = os.listdir(test_label_dir)\n",
    "\n",
    "# Ensure files are sorted in the same order\n",
    "test_data_files.sort()\n",
    "test_label_files.sort()\n",
    "\n",
    "# Initialize lists to store test features and labels\n",
    "test_matrixOfVideos = []\n",
    "test_popularity_labels = []\n",
    "test_file_names = []\n",
    "\n",
    "for test_data_file, test_label_file in zip(test_data_files, test_label_files):\n",
    "    # Load features from test data file\n",
    "    test_features = np.load(os.path.join(test_data_dir, test_data_file))\n",
    "\n",
    "    # Load label from test label file\n",
    "    test_label = np.load(os.path.join(test_label_dir, test_label_file))\n",
    "    test_file_names.append(test_data_file)\n",
    "    test_matrixOfVideos.append(test_features)\n",
    "    test_popularity_labels.append(test_label)\n",
    "\n",
    "# Pad sequences for test data\n",
    "# Assuming your model is already trained and loaded\n",
    "# Evaluate the model on the test data\n",
    "test_padded = pad_sequences(test_matrixOfVideos, dtype='float32', padding='post', truncating='post')\n",
    "test_popularity_labels = np.array(test_popularity_labels)\n",
    "\n",
    "# Reshape test_popularity_labels to match the shape of test_predictions\n",
    "test_popularity_labels = np.repeat(test_popularity_labels, test_padded.shape[1], axis=1)\n",
    "test_popularity_labels = np.expand_dims(test_popularity_labels, axis=-1)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss = model.evaluate(test_padded, test_popularity_labels)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions = model.predict(test_padded)\n",
    "\n",
    "# Evaluate additional metrics if needed\n",
    "# For example, Mean Absolute Error (MAE) on test data\n",
    "test_mae = np.mean(np.abs(test_predictions - test_popularity_labels))\n",
    "print(\"Test Mean Absolute Error:\", test_mae)\n",
    "\n",
    "# Print predictions and original labels for each test video\n",
    "existing_video_id = \"\"\n",
    "existing_window_id = \"\"\n",
    "for i in range(len(test_predictions)):\n",
    "    match = re.match(r\"matrix_of_video_(\\d+)_(\\d+).npy\", test_file_names[i])\n",
    "\n",
    "    if match:\n",
    "        video_id = int(match.group(1))\n",
    "        window_id = int(match.group(2))\n",
    "\n",
    "        existing_window_id = window_id\n",
    "        if existing_video_id != video_id:\n",
    "            existing_video_id = video_id\n",
    "            print(\"Video ID:\", video_id)\n",
    "            print(f\"Window ID: {window_id}\")\n",
    "    print(f\"Video {i} - Prediction: {test_predictions[i][0]}, Original Label: {test_popularity_labels[i][0][0]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
