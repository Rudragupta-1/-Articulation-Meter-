{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import variation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import concurrent.futures\n",
    "\n",
    "# Load the existing data from the Excel file\n",
    "excel_file = '/home/rudra/Documents/GitHub/Articulation-Meter/Project Files/ted _data.xlsx'\n",
    "sheet_name = 'Sheet1'\n",
    "df = pd.read_excel(excel_file, sheet_name=sheet_name)\n",
    "\n",
    "# Drop last two columns (assuming these are duration, likes, and views)\n",
    "df = df.iloc[:, :-2]\n",
    "\n",
    "# Restrict to the first 200 rows\n",
    "df = df.head(200)\n",
    "\n",
    "# Function to convert likes to numerical values (provided for reference)\n",
    "def convert_likes(like):\n",
    "  if isinstance(like, str):\n",
    "    if 'K' in like:\n",
    "      return float(like.replace('K', '')) * 1000\n",
    "    elif 'M' in like:\n",
    "      return float(like.replace('M', '')) * 1000000\n",
    "    else:\n",
    "      return float(like)\n",
    "  return like\n",
    "\n",
    "# Convert likes to numerical values (assuming 'likes' column exists)\n",
    "df['likes'] = df['likes'].apply(convert_likes)\n",
    "\n",
    "# Function to extract audio features\n",
    "def extract_audio_features(audio_path):\n",
    "  # Load the audio file\n",
    "  y, sr = librosa.load(audio_path)\n",
    "\n",
    "  # Calculate new features\n",
    "  features = {}\n",
    "  # features['chroma_stft'] = np.mean(librosa.feature.chroma_stft(y=y, sr=sr))\n",
    "  # features['rmse'] = np.mean(librosa.feature.rms(y=y))\n",
    "  features['spectral_centroid'] = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr))\n",
    "  features['spectral_bandwidth'] = np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr))\n",
    "  features['rolloff'] = np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr))\n",
    "  features['zero_crossing_rate'] = np.mean(librosa.feature.zero_crossing_rate(y))\n",
    "\n",
    "  # Include existing features (assuming these are relevant)\n",
    "  # features['energy'] = np.sum(librosa.stft(y) ** 2)  # Energy\n",
    "  # features['mfccs'] = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13).mean(axis=1)  # MFCCs (mean)\n",
    "  features['pitch'] = np.max(librosa.piptrack(y=y, sr=sr)[0])  # Pitch\n",
    "  # features['speech_rate_variation'] = variation(np.diff([d[1]-d[0] for d in librosa.effects.split(y=y)])) if len(librosa.effects.split(y=y)) > 1 else 0.0  # Speech rate variation\n",
    "  # features['articulation_rate'] = len(librosa.effects.split(y=y)) / librosa.get_duration(y=y)  # Articulation rate\n",
    "  # features['frequency'] = sr / len(y)  # Frequency\n",
    "\n",
    "  return features\n",
    "# Directory to store the audio files\n",
    "audio_dir = '/home/rudra/Documents/GitHub/Articulation-Meter/Project Files/audio/audio_analysis/'\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(audio_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame containing YouTube video codes\n",
    "# Example:\n",
    "# df = pd.DataFrame({'youtube_video_code': ['dQw4w9WgXcQ', '3JZ_D3ELwOQ', ...]})\n",
    "\n",
    "# Directory to save audio files\n",
    "audio_dir = '/home/rudra/Documents/GitHub/Articulation-Meter/Project Files/audio/audio_analysis'\n",
    "\n",
    "# Function to process a single video\n",
    "def process_video(video_code):\n",
    "    url = f\"https://www.youtube.com/watch?v={video_code}\"\n",
    "    output_template = os.path.join(audio_dir, f\"{video_code}.%(ext)s\")\n",
    "\n",
    "    # Define the command for downloading and converting audio\n",
    "    command = [\n",
    "        \"yt-dlp\",\n",
    "        \"-f\", \"bestaudio\",\n",
    "        \"--extract-audio\",\n",
    "        \"--audio-format=wav\",\n",
    "        \"-o\", output_template,\n",
    "        url\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        # Run the command for downloading and converting audio\n",
    "        subprocess.run(command, check=True)\n",
    "        print(f\"Successfully downloaded and converted: {url}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Failed to download {url}: {e}\")\n",
    "\n",
    "# Process the first 200 video links concurrently\n",
    "if __name__ == '__main__':\n",
    "    video_codes = df['youtube_video_code'][:200]\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=16) as executor:\n",
    "        # Map the function to the video codes\n",
    "        executor.map(process_video, video_codes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialize lists to store results\n",
    "pitches = []\n",
    "spectral_centroids = []\n",
    "spectral_bandwidths = []\n",
    "rolloffs = []\n",
    "zero_crossing_rates = []\n",
    "likes_list = []\n",
    "views_list = []\n",
    "\n",
    "# Process each audio file in the directory corresponding to the first 200 rows\n",
    "audio_files_info = [(row['youtube_video_code'], row['likes'], row['views'], os.path.join(audio_dir, f\"{row['youtube_video_code']}.wav\")) for _, row in df.iterrows()]\n",
    "\n",
    "for video_code, like, view, audio_path in audio_files_info:\n",
    "    if os.path.exists(audio_path):\n",
    "        # Extract audio features\n",
    "        features = extract_audio_features(audio_path)\n",
    "\n",
    "        # Store the features and the like value\n",
    "        pitches.append(features.get('pitch', None))  # Handle missing values\n",
    "        spectral_centroids.append(features['spectral_centroid'])\n",
    "        spectral_bandwidths.append(features['spectral_bandwidth'])\n",
    "        rolloffs.append(features['rolloff'])\n",
    "        zero_crossing_rates.append(features['zero_crossing_rate'])\n",
    "        likes_list.append(like)\n",
    "        views_list.append(view)\n",
    "    else:\n",
    "        # Handle missing audio files\n",
    "        pitches.append(None)\n",
    "        spectral_centroids.append(None)\n",
    "        spectral_bandwidths.append(None)\n",
    "        rolloffs.append(None)\n",
    "        zero_crossing_rates.append(None)\n",
    "        likes_list.append(None)\n",
    "        views_list.append(None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame to store the results\n",
    "audio_df = pd.DataFrame({\n",
    "    'Likes': likes_list,\n",
    "    'Views': views_list,\n",
    "    'Pitch': pitches,\n",
    "    'Spectral Centroid': spectral_centroids,\n",
    "    'Spectral Bandwidth': spectral_bandwidths,\n",
    "    'Rolloff': rolloffs,\n",
    "    'Zero Crossing Rate': zero_crossing_rates,\n",
    "})\n",
    "\n",
    "# Normalize audio features using MinMaxScaler\n",
    "scaler_minmax = MinMaxScaler()\n",
    "audio_df[['Pitch', 'Spectral Centroid', 'Spectral Bandwidth', 'Rolloff', 'Zero Crossing Rate']] = scaler_minmax.fit_transform(\n",
    "    audio_df[['Pitch', 'Spectral Centroid', 'Spectral Bandwidth', 'Rolloff', 'Zero Crossing Rate']]\n",
    ")\n",
    "\n",
    "# Write the final DataFrame to a new Excel file\n",
    "audio_df.to_excel('merged_excel_file.xlsx', index=False)\n",
    "\n",
    "# Display the DataFrame to verify (optional)\n",
    "print(audio_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
