{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "import librosa\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "# import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Excel file into a pandas DataFrame\n",
    "file_path = '/home/amit-talmale/Documents/GitHub/Articulation-Meter/Project Files/merged_excel_file.xlsx'  # Replace with your Excel file path\n",
    "df = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change duration in sec. to min.\n",
    "\n",
    "df['duration'] = df['duration'] / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treatment outliers by mean\n",
    "\n",
    "columns = ['views', 'duration']\n",
    "\n",
    "for i in columns:\n",
    "  iqr = df[i].quantile(0.75)-df[i].quantile(0.30)\n",
    "  df[i] = df[i].mask(df[i]>(df[i].quantile(0.75)+1.5*iqr), df[i].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's see the numerical column again after treating outliers\n",
    "\n",
    "columns = ['views', 'duration']\n",
    "n = 1\n",
    "plt.figure(figsize=(18,12))\n",
    "\n",
    "for i in columns:\n",
    "  plt.subplot(3,3,n)\n",
    "  n=n+1\n",
    "  sns.boxplot(df[i])\n",
    "  plt.title(i)\n",
    "  plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Define a function to convert string representations of arrays to numpy arrays\n",
    "def convert_to_array(mfccs_str):\n",
    "    # Extract numerical values from the string using regular expressions\n",
    "    values = re.findall(r'[-+]?\\d*\\.\\d+|\\d+', mfccs_str)\n",
    "    # Ensure that the number of values is divisible by 13 (assuming 13 MFCCs features)\n",
    "    num_values = len(values)\n",
    "    if num_values % 13 != 0:\n",
    "        # Pad or truncate the values to make the number divisible by 13\n",
    "        target_length = num_values + (13 - (num_values % 13))\n",
    "        if num_values < target_length:\n",
    "            values += ['0'] * (target_length - num_values)\n",
    "        else:\n",
    "            values = values[:target_length]\n",
    "    # Convert the values to float and reshape into a numpy array\n",
    "    mfccs_array = np.array(values, dtype=float).reshape(-1, 13)\n",
    "    return mfccs_array\n",
    "\n",
    "# Convert MFCCs strings to numpy arrays\n",
    "df['MFCCs'] = df['MFCCs'].apply(convert_to_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Flatten MFCCs arrays and add them as separate features\n",
    "mfcc_columns = [f'mfcc_{i}' for i in range(df['MFCCs'].iloc[0].shape[1])]\n",
    "for i, col in enumerate(mfcc_columns):\n",
    "    df[col] = df['MFCCs'].apply(lambda x: x[:, i])\n",
    "\n",
    "# Select relevant columns for clustering\n",
    "selected_columns = ['duration', 'likes', 'views', 'Energy', 'Pitch', 'Speech Rate Variation', 'Articulation Rate', 'Frequency'] + mfcc_columns\n",
    "data_for_clustering = df[selected_columns]\n",
    "\n",
    "# Exclude non-numeric columns before scaling\n",
    "numeric_columns = data_for_clustering.select_dtypes(include=['float64', 'int64']).columns\n",
    "data_for_scaling = data_for_clustering[numeric_columns]\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data_for_scaling)\n",
    "\n",
    "# Perform clustering using KMeans\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "clusters = kmeans.fit_predict(scaled_data)\n",
    "\n",
    "# Add the cluster labels to the DataFrame\n",
    "df['cluster'] = clusters\n",
    "\n",
    "# Print the cluster centers\n",
    "print(\"Cluster Centers:\")\n",
    "print(scaler.inverse_transform(kmeans.cluster_centers_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Perform PCA for dimensionality reduction to 2D\n",
    "pca = PCA(n_components=2)\n",
    "reduced_data = pca.fit_transform(scaled_data)\n",
    "\n",
    "# Plot the clusters\n",
    "plt.figure(figsize=(10, 6))\n",
    "for cluster in range(3):\n",
    "    plt.scatter(reduced_data[clusters == cluster, 0], reduced_data[clusters == cluster, 1], label=f'Cluster {cluster}')\n",
    "plt.title('Clustering Visualization using PCA')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Example for understand the clustring\n",
    "\n",
    "# Cluster 0:\n",
    "\n",
    "# Duration: Approximately 3.75 units\n",
    "# Likes: Approximately 126,860\n",
    "# Views: Approximately 2,163,990\n",
    "# Energy: Approximately 79,282,684\n",
    "# Pitch: Approximately 3,999.72\n",
    "# Speech Rate Variation: Approximately 4.92%\n",
    "# Articulation Rate: Approximately 0.02%\n",
    "# Frequency: Approximately 0.\n",
    "# Cluster 1:\n",
    "\n",
    "# Duration: Approximately 3.89 units\n",
    "# Likes: Approximately 26,051\n",
    "# Views: Approximately 882,478\n",
    "# Energy: Approximately 82,660,148\n",
    "# Pitch: Approximately 3,999.74\n",
    "# Speech Rate Variation: Approximately -0.19%\n",
    "# Articulation Rate: Approximately 0.01%\n",
    "# Frequency: Approximately 0.004%\n",
    "# Cluster 2:\n",
    "\n",
    "# Duration: Approximately 3.54 units\n",
    "# Likes: Approximately 35,764\n",
    "# Views: Approximately 1,000,438\n",
    "# Energy: Approximately 74,820,612\n",
    "# Pitch: Approximately 3,999.43\n",
    "# Speech Rate Variation: Approximately 0.28%\n",
    "# Articulation Rate: Approximately 0.01%\n",
    "# Frequency: Approximately 0.006%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
