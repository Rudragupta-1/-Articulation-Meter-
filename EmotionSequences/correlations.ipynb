{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your data\n",
    "data = pd.read_excel(\"btp_list.xlsx\")\n",
    "print(data.head())  # Print the first few rows of the DataFrame\n",
    "print(data.dtypes)  # Check the data types to see what pandas is interpreting them as\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load your data\n",
    "data = pd.read_excel(\"btp_list.xlsx\")\n",
    "\n",
    "# Function to process a string of numbers separated by commas\n",
    "def process_number_list(cell):\n",
    "    try:\n",
    "        # If the cell is not a string (already a numeric type), return it as is\n",
    "        if not isinstance(cell, str):\n",
    "            return cell\n",
    "        # Split the string on commas\n",
    "        numbers = cell.split(\", \")\n",
    "        # Convert each to float and compute the average\n",
    "        numbers = [float(num) for num in numbers]\n",
    "        return np.std(numbers)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing cell: {cell} with error {e}\")\n",
    "        return np.nan  # Return NaN for problematic conversions\n",
    "\n",
    "# Columns that need processing (assuming all these might have the string lists)\n",
    "columns = [\"shoulder_midpoints\", \"head_turn_angles\", \"left_hand\", \"right_hand\"]\n",
    "\n",
    "# Apply the processing function to each relevant column\n",
    "for column in columns:\n",
    "    data[column] = data[column].apply(process_number_list)\n",
    "\n",
    "# Check results\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "correlation_matrix = data[['shoulder_midpoints', 'head_turn_angles', 'left_hand', 'right_hand']].corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(\"Correlation Matrix:\")\n",
    "print(correlation_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Drop rows with any NaN values in specified columns\n",
    "cleaned_data = data.dropna(subset=['shoulder_midpoints', 'head_turn_angles', 'left_hand', 'right_hand'])\n",
    "\n",
    "# Standardizing the features\n",
    "x = cleaned_data[['shoulder_midpoints', 'head_turn_angles', 'left_hand', 'right_hand']].values\n",
    "x = StandardScaler().fit_transform(x)\n",
    "\n",
    "# Applying PCA\n",
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(x)\n",
    "principalDf = pd.DataFrame(data=principalComponents, columns=['Principal Component 1', 'Principal Component 2'])\n",
    "\n",
    "# Combining with other data for a comprehensive view\n",
    "finalDf = pd.concat([principalDf, cleaned_data[['youtube_video_code', 'category']]], axis=1)\n",
    "\n",
    "# Print results\n",
    "print(finalDf.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Imputing missing values\n",
    "imputer = SimpleImputer(strategy='mean')  # Can also use median or most_frequent\n",
    "imputed_data = imputer.fit_transform(data[['shoulder_midpoints', 'head_turn_angles', 'left_hand', 'right_hand']])\n",
    "\n",
    "# Standardizing the features\n",
    "x = StandardScaler().fit_transform(imputed_data)\n",
    "\n",
    "# Applying PCA\n",
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(x)\n",
    "principalDf = pd.DataFrame(data=principalComponents, columns=['Principal Component 1', 'Principal Component 2'])\n",
    "\n",
    "# Combining with other data for a comprehensive view\n",
    "finalDf = pd.concat([principalDf, data[['youtube_video_code', 'category']].reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Print results\n",
    "print(finalDf.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(finalDf['Principal Component 1'], finalDf['Principal Component 2'])\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.title('PCA Result Plot')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
